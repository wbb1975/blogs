## 处理瞬态错误的建议

本指南描述了在你的云应用中处理瞬态错误的建议，所有与远程服务和资源通讯的程序必须对瞬态错误敏感。这一点对于运行于云上的应用尤其重要--由于环境及通过 internet 连接的本性，这种类型的错误遇见得更频繁一些。瞬态错误包括至组件和服务的网络连接的短暂丢失，服务暂时不可用，以及服务繁忙时的超时。这些错误是自纠正的，因此在一个合适的延迟后，采取某种行动是可能成功的。

本文提供瞬态错误处理的通用指南。关于在你的应用中为处理瞬态错误而实现重试的信息，请参见[重试模式](https://learn.microsoft.com/en-us/azure/architecture/patterns/retry)，当你使用Azure 服务时，请参见[Azure 服务重试指南](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific)。

## 瞬态错误

瞬态错误可以在任何环境，任何平台或操作系统，任何种类的应用中发生。对于运行于本地 on-premises 基础设施上的方案，应用和组件的性能和可用性典型第通过昂贵且低使用率的硬件冗余来保证，并且组件和资源相互离得很近。这种方式使得错误发生的概率降低，但瞬态错误仍会出现，就像由不可预测事件如外部电力中断，网络问题或者灾难场景导致的服务中断。

云托管，如私有云系统，通过使用共享资源，冗余，自动故障转移，以及跨多个商用计算节点的动态资源分配来提供更高的综合可用性。但是，由于云环境的本性，瞬态错误更有可能发生。一下原因可以解释这个现象：

- 在云环境中许多资源是共享的，对这些资源的访问是被节流的以保护这些资源。当负载达到一个特定级别，或者最大吞吐量达到时，某些服务会拒绝连接以允许已有请求的处理，以及维护该服务对所有用户的性能。节流帮忙维护对邻居以及使用共享服务的其它租户的服务质量。
- 云环境使用了大量的商用硬件单元，它们通过跨多个计算单元和基础设施组件动态分配负载来实现性能指标。他们通过自动回收或替换失效单元来实现可靠性。由于这种动态本性，瞬态错误或暂时连接失败可能会偶尔发生。
- 通常有很多硬件组件，抱愧网络基础设施如路由器和负载均衡器，它们位于应用和应用使用的服务和资源之间。这些额外的基础设施偶尔也可能引入额外的连接延时和瞬态连接错误。
- 客户端与服务器端的网路i状况可能是变化的，尤其是跨 internet 通讯。即使是在 on-premises 场景，重负载也会拖慢通讯并导致间歇性连接失败。

瞬态错误对应用的观察到的可用性又重大影响，即使它已经在一个稳定的环境里充分测试过。为了确保云托管应用可靠地运作，你需要确保它们对下面的挑战做出了适当的反应：

- 当错误发生时，应用必须能检测到它们并判断错误是暂时的，是持续很长时间的还是终端故障。当错误发生时，不同资源可能返回不同的反应，这些反应可能会根据不同运作背景而不同。例如，一个应用在读存储发生错误的反应绝对不同于写存储。许多资源和服务对于瞬态错误都有很好的文档。但是，当此类信息不可得时，你就很难揭示错误的本质，并判断错误是否是暂时的。
- 应用如果能够判断错误可能是临时的，那么他就必须重试操作。它必须追踪操作充实的次数。
- 应用必须为重试采用一个合适的策略。策略制定了应用重试的次数，每次重试的时间间隔，以及每次重试失败后采取的措施。合适的重试次数以及间隔是很难确定的。策略可依据资源类型，资源的当前操作条件，以及应用二改变。

下面的指南可帮助你为你的应用设计合适的瞬态错误处理机制。

## 重试实现

### 决定是否有内建重试机制

- 许多服务提供 SDK 或 客户端库，其中包含瞬态错误机制。它使用的重试策略典型地是根据目标服务的性质和需求量身定制的。可选地，服务的REST 接口可能返回信息帮助你判断重试是否是合适的，以及下一次重试之前应该等待多久。
- 如果可用，你应该使用内建重试机制，除非你有特定的且完全理解的需求使得一个不同的重试行为更合适。

### 决定一个操作是否适合重试

- 只有当错误是瞬态（典型地由错误的性质指示）且至少重试时操作有可能成功时才需要执行重试。试着重试一个无效的操作毫无意义，比如更新数据库中一个不存在的数据项，又比如向一个遭受致命错误的服务或资源发送请求。
- 通常只有当你能够决定你如此做的全部效果，情况已经充分理解且可验证时才实现重试。否则，让调用代码实现重试。记住从资源和服务返回且在你的控制之外的错误会随时间而演化，而且你可能需要回顾你的瞬态错误检验逻辑。
- 当你创建服务和组件时，考虑实现错误代码和消息以帮助客户决定他们是否应该重试失败的重做。尤其指示客户是否应该重试操作（可能通过返回一个isTransient值），并建议一个重试之前的合适的延迟。如果你构建一个 web 服务，考虑在你的服务契约里返回一个自定义错误。虽然普通客户可能不会读到这些错误，它们对自定义客户端的创建是有用的。

### 决定合适的重试次数和间隔

- 根据用例类型来优化重试册数和间隔。如果你没有重试足够次数，应用可能不会完成操作且还会失败。如果你重试太多次数，或重试间隔过短，应用可能长时间持有资源如线程，连接和内存，这反过来反而影响了应用的健康状态。
- 调整时间间隔和重试次数使其适应操作类型。例如，如果操作是用户交互的一部分，间隔应该较短且有限重试。使用这种方式，你可以避免用户持有连接等待回复返回，从而降低其它用户的可用性。如果操作是一个长时间运行的关键工作流的一部分，放弃和重启进程昂贵或费时，它就适合等待更长时间且重试更多次数。
- 记住决定合适的重试间隔是设计一个成功的策略里最困难的部分。典型的策略使用如下重试间隔类型：
  + 指数退避（Exponential back-off）：在第一次重试前等待较短的时间，但在后续每次重试间隔指数增长重试间隔。例如，可能在 3 秒，12 秒，30 秒后重试操作，诸如此类。为了深入改善这个策略，你可以在指数退避中加入抖动。抖动在每次重试间隔中引入随机延迟，它帮助防止多个客户同时重试导致负载增高。
  + 增量间隔（Incremental intervals）：在第一次重试前等待较短的时间，但在后续每次重试间隔增量增加重试时间。例如，可能在 3 秒，7 秒，13 秒后重试操作，诸如此类。
  + 常规间隔（Regular intervals）：应用在每次重试间等待相同的时间。例如每 3 秒钟重试一次。。
  + 立即重试（Immediate retry）：有时候瞬态错误是短暂的，可能由一个事件如网络包冲突或者一个硬件组件的峰值引起。在这种情况下，立即重试是合适的，因为如果此时错误已经被清除，应用重发请求就可能成功。但是，永远不要立即重试两次。如果立即重试失败，你应该切换到别的策略，如指数退避重试或回滚。
  + 随机化（Randomization）：之前列出的任意重试策略可以引入随机化以防止多个客户在同一时间出发下一次重试。例如，一个实例可能在 3 秒, 11 秒, 28 秒诸如此类的间隔后重试，另一个实例可能在 4 秒, 12 秒, 26 秒诸如此类的间隔后重试。随机化可以与其它策略绑定，是一个有用的技术。
- 一个通用准则，为后台操作使用使用指数退避加抖动策略，为交互操作立即重试或常规间隔重试策略。在两种情况下，你都需要选择重试次数和延迟使得所有重试的最大延迟满足最终端到端延迟需求。
- 考虑一个重试操作整体超时的所有影响因素。这些因素包括它花费在一个失败连接期待产生回复（典型地是由客户端设置的超时值）的时间，重试间隔，最大重试次数等。这些时间的总和可能导致总体操作时间变长，尤其当你使用指数延迟策略时，每次失败后的重试间隔飞速增长。如果一个进程必须满足一个 SLA（service-level agreement），整体运行时间，包括所有超时和延迟，必须在 SLA 定义的限制内。
- 不要实现过于激进的重试策略。这些策略要么间隔太短，要么重试太频繁。它们对目标资源和服务反而有反效果。这些策略可能阻止资源和服务从一个过载状态恢复，他将会继续堵塞或者拒绝请求。这种场景导致一个恶性循环，越来越多的请求被发送至该资源和服务，最终其恢复能力被极大削弱。
- 当你选择重试间隔以避免立即开启（例如，如果超时时间和重试间隔一致）下一次重试时，请考虑操作超时之。同时，考虑你是否需要保持总体操作时间（超时加重试间隔）在一个特定总体时间之下。如果一个超时拥有一个或长或短的超时，超时将影响等待时长或者重试频率。
- 使用异常类型和它含有的数据，从服务返回的错误码及消息来优化重试次数和间隔。例如，某些异常或错误码（像 HTTP 代码 503, 服务不可用, 恢复中带有稍后重试的消息头）可能指示错误将持续多长时间，或者服务已经失败，且将不会回复稍后的任何信息。
- 考虑使用死信队列的方式确保当重试用尽后所有输入调用信息不会丢失。

### 避免反模式

- 在大部分情况下，避免实现中重试代码在不同层重复出现。避免在设计中包含重试机制级联，或者在一个涉及多级请求的操作中在每一阶段重试，除非你有特别的需求需要如此做。在这些异常情况下，使用防止过多重试和过长间隔的策略，并确认你理解选择的后果。例如，假设一个组件向另一个组件发起了请求，后者需要请求目标服务。如果你实现了两个组件每次调用都重试三次，那么对目标服务来讲就有九次重试。许多资源或服务实现了内置重试机制。如果你期待在一个更高级别上实现重试，你应该调查如何禁用或修改这些机制，
- 永远也不要实现一个不结束的重试机制。如此做可能阻止资源或服务从过载状态恢复，并导致长时间限流或拒绝连接。使用有限次重试，或者一个模式如[断路器](https://learn.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker) 以允许服务恢复。
- 永远也不要实现立即重试超过一次。
- 避免使用常规重试间隔访问 Azure 资源或服务，尤其你由很高的重试次数。这种场景下做好的方式是指数退避策略加断路器。
- 防止同一客户的多个实例，或者不同客户的多个实例同时发起重试。如果这种场景有可能发生，在你的重试间隔中引入随机化。

### 测试重试策略与实现

在尽可能多的环境里充分测试你的重试策略，尤其在你的应用和它访问的资源或服务处于极端负载情况下。在测试中检查其行为，你可以：

- 特意在你的非产品环境和产品环境通过[混沌工程和故障注入](https://learn.microsoft.com/en-us/azure/well-architected/reliability/testing-strategy#use-fault-injection-and-chaos-engineering) 引入瞬态错误。例如，发送无效请求或添加代码以监测测试请求并回复不同类型的错误。
- 创建一个资源或服务的 mockup，它返回真实服务可能返回的各种错误。覆盖你的重试机制设计检测返回的所有错误。
- 对于你创建和部署的自定义服务，通过临时禁止或过载服务来强制瞬态错误发生（不要试着过载任何 Azure 的共享服务和资源）。
- 在你的自动化测试中，使用库或方案以拦截或修改网络流量来复制不利场景。例如，测试可能增加额外的往返时间，丢包，改包头，甚至修改请求本身的负载。这样做允许对失败条件的一个子集做决定性测试，包括瞬态错误和其它类型错误。
- 当测试你的客户端 Web 应用的可靠性至瞬态错误，使用浏览器开发工具或你的测试框架的能力来[模拟](https://playwright.dev/docs/network#network-mocking)或[拦阻](https://learn.microsoft.com/en-us/microsoft-edge/devtools-guide-chromium/network/#block-requests) 网络请求。
- 执行高负载系数和并发测试以确保重试机制和策略在这些情况下正常工作。这些测试确保重试没有对客户的操作产生反效果，或者在请求见产生交叉污染。

### 管理重试策略配置

- 一个重试策略是你的重试策略所有元素的组合。它定义了发现机制用于决定一个错误是否可能是瞬态的，使用的间隔类型（比如常规，指数退避，以及随机化），实际间隔值，重试次数。
- 在许多地方实现重试，即使是最简单的应用，在更复杂应用的每一层。不要在许多地方硬编码每个策略的元素，考虑在中央点存储所有策略。例如，存储重试次数和间隔值在应用配置文件中，在运行时读取他们，并编程构建重试策略。如此更容易管理设置，修改和调优这些值，从而更好应对修改的需求和场景。但是，设计系统存储这些值而不是每次都再从配置文件读取，当不能从配置中读取时应设置合适的默认值。
- 将需要在运行时构建重试策略的值存储到应用的配置系统中，如此你可以修改它们而无需重启应用。
- 利用你使用的客户端 API 中可用的内建和默认重试策略，但只有当它们适合你的场景时才选择它们。这些策略典型地很通用，在某些场景下，它们就是你所需要的；但在别的场景下，它们可能不同提供全部选项来满足你的需求。为了决定最合适的值，你需要执行测试以决定这些设置如何影响你的应用。

### 记录和追踪瞬态和非瞬态错误

- 作为你的重试策略的一部分，包括异常处理和指令如记录重试。一个偶尔的瞬态错误和重试并不指示问题。但是，定期的且不断增长的重试通常指示有问题，它可能导致了一次失败，或者降低应用的性能和可用性。
- 将瞬态错误记录成一个警告而非一个错误，如此监控系统就不会监测到它们，通常错误会触发警报。
- 考虑在你的日志项中用来指示重试是否来自一个服务限流，或者由另一个错误引发，如连接失败，这样你就可以通过分析数据来区分它们。限流错误数目增多经常指示应用有设计缺陷，或者需要切换到提供专用硬件的溢价服务。
- 考虑测量和记录包含重试机制的操作的总体耗时。这个指标是瞬态错误的总体效果的很好的指示，事关用户反应时间，处理延迟，应用用户用例的效率。也记录重试发生的次数，如此你就能理解反应时间的影响因素。
- 考虑实现一个监测系统，它可以在操作成功前当失败率数字，平均重试次数，或整体消耗时间不断增长时触发警报。

### 管理持续失败的操作

### 优化重试实现

## Azure 便利设施

大多数 Azure 服务和客户端 SDK 提供了重试机制。但是，这些机制是不一样的，每种服务都有不同的特征和需求，每种重试机制都针对特定服务进行了调整。下面章节对一些常用 Azure 服务的重试机制特性进行了总结。

服务|能力|策略配置|范畴|监测功能（Telemetry features）
--|--|--|--|--
[Microsoft Entra ID](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#azure-active-directory)|微软认证库 (MSAL)中原生|嵌入到 MSAL 库中|内部（Internal）|None
[Azure Cosmos DB](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#azure-cosmos-db)|服务原生|不可配置|全局（Global）|TraceSource
[Azure Data Lake Storage](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#data-lake-store)|客户端原生|不可配置|单独操作|None
[Azure Event Hubs](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#event-hubs)|客户端原生|编程|客户端|None
[Azure IoT Hub](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#iot-hub)|客户端 SDK 原生|编程|客户端|None
[Azure Cognitive Search](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#azure-search)|客户端原生|编程|客户端|ETW 或 custom
[Azure Service Bus](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#service-bus)|客户端原生|编程|NamespaceManager, MessagingFactory, 客户端|	ETW
[Azure Service Fabric](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#service-fabric)|客户端原生|编程|客户端|None
[Azure SQL Database with ADO.NET](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#sql-database-using-adonet)|[Polly](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#transient-fault-handling-with-polly)|声明和编程|单个申明或代码块|Custom
[SQL Database with Entity Framework](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#sql-database-using-entity-framework-6)|客户端原生|编程|每个AppDomain全局（Global per AppDomain）|	None
[SQL Database with Entity Framework Core](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#sql-database-using-entity-framework-core)|	客户端原生|编程|个AppDomain全局（Global per AppDomain）|None
[Azure Storage](https://learn.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#azure-storage)|客户端原生|编程|客户端和单个操作|TraceSource

## 示例

参考 [Reliable web app pattern for .NET](https://learn.microsoft.com/en-us/azure/architecture/web-apps/guides/reliable-web-app/dotnet/apply-pattern) 作为一个示例，它使用本文介绍的许多模式。GitHub 上也有一个[参考实现](https://github.com/Azure/reliable-web-app-pattern-dotnet)。

## Reference
- [Recommendations for handling transient faults](https://learn.microsoft.com/en-us/azure/well-architected/design-guides/handle-transient-faults)
- [Circuit Breaker pattern](https://learn.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker)
- [Retry pattern](https://learn.microsoft.com/en-us/azure/architecture/patterns/retry)
- [Throttling pattern](https://learn.microsoft.com/en-us/azure/architecture/patterns/throttling)
- [Compensating Transaction pattern](https://learn.microsoft.com/en-us/azure/architecture/patterns/compensating-transaction)
- [A blog post on idempotency patterns](https://blog.jonathanoliver.com/idempotency-patterns)
- [Connection Resiliency](https://learn.microsoft.com/en-us/ef/core/miscellaneous/connection-resiliency)
- [Inject mock services](https://learn.microsoft.com/en-us/aspnet/core/test/integration-tests#inject-mock-services)
- [Dead-letter queue pattern](https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dead-letter-queues)
